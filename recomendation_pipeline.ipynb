{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "from surprise import Dataset, Reader\n",
    "from surprise import BaselineOnly\n",
    "\n",
    "from surprise.model_selection import cross_validate\n",
    "from surprise import SVD, KNNBasic, SVDpp, NMF, KNNBaseline, KNNWithMeans, KNNWithZScore\n",
    "from surprise.model_selection import GridSearchCV\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise import dump\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funçoes Auxiliares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_svg_algo(prediction_algorithm , dataset, verbose=False):\n",
    "    param_grid_svg = {\n",
    "        'n_factors': [20, 50, 100],\n",
    "        'n_epochs': [5, 10, 20, 30, 40, 50],\n",
    "        \"lr_all\": [0.01, 0.2, 0.05, 0.001, 0.002, 0.005],\n",
    "        \"reg_all\": [0.4, 0.6]\n",
    "    }\n",
    "    \n",
    "    param_grid_nmf = {\n",
    "        'n_factors': [20, 50, 100],\n",
    "        'n_epochs': [5, 10, 20, 30, 40, 50],\n",
    "        \"lr_all\": [0.01, 0.2, 0.05, 0.001, 0.002, 0.005],\n",
    "        \"reg_all\": [0.4, 0.6]\n",
    "    }\n",
    "   \n",
    "    param_grid = param_grid_nmf if type(prediction_algorithm) == NMF else param_grid_svg\n",
    "   \n",
    "    gs = GridSearchCV(\n",
    "            prediction_algorithm,\n",
    "            param_grid,\n",
    "            measures=['rmse', 'mae'],\n",
    "            cv=10,\n",
    "            n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    gs.fit(dataset)\n",
    "    \n",
    "    if (verbose):\n",
    "        print(f\"SVD RMSE SCORE: {gs.best_score['rmse']}\")\n",
    "        print(f\"SVD MAE SCORE: {gs.best_score['mae']}\")\n",
    "        print(f\"SVD BEST PARAMS RMSE: {gs.best_params['rmse']} \\n\")\n",
    "        print(f\"SVD BEST PARAMS MAE: {gs.best_params['mae']} \\n\")\n",
    "\n",
    "    algo = gs.best_estimator[\"rmse\"]\n",
    "    return algo\n",
    "\n",
    "\n",
    "def build_knn_algo(prediction_algorithm, dataset, verbose=False):\n",
    "    \n",
    "    param_grid = {\n",
    "        'k': [10, 20, 30, 40, 50, 100, 150, 200],\n",
    "        'sim_options': {\n",
    "            \"name\": [\"msd\", \"cosine\", \"pearson\"],\n",
    "            \"user_based\": [False],\n",
    "            'verbose' : [verbose]\n",
    "        },\n",
    "    }\n",
    "   \n",
    "    gs = GridSearchCV(\n",
    "        prediction_algorithm,\n",
    "        param_grid,\n",
    "        measures=['rmse', 'mae'],\n",
    "        cv=10,\n",
    "        n_jobs=1\n",
    "    )\n",
    "    \n",
    "    gs.fit(dataset)\n",
    "    \n",
    "    if (verbose):\n",
    "        print(f\"KNN RMSE SCORE: {gs.best_score['rmse']}\")\n",
    "        print(f\"KNN MAE SCORE: {gs.best_score['mae']}\")\n",
    "        print(f\"KNN BEST PARAMS: {gs.best_params['rmse']} \\n\")\n",
    "        print(f\"KNN BEST PARAMS: {gs.best_params['mae']} \\n\")\n",
    "\n",
    "    algo = gs.best_estimator[\"rmse\"]\n",
    "    return algo\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_n(predictions, n=10):\n",
    "    \"\"\"Return the top-N recommendation for each user from a set of predictions.\n",
    "\n",
    "    Args:\n",
    "        predictions(list of Prediction objects): The list of predictions, as\n",
    "            returned by the test method of an algorithm.\n",
    "        n(int): The number of recommendation to output for each user. Default\n",
    "            is 10.\n",
    "\n",
    "    Returns:\n",
    "    A dict where keys are user (raw) ids and values are lists of tuples:\n",
    "        [(raw item id, rating estimation), ...] of size n.\n",
    "    \"\"\"\n",
    "\n",
    "    top_n = defaultdict(list)\n",
    "    for uid, iid, true_r, est, _ in predictions:\n",
    "        top_n[uid].append((iid, est))\n",
    "\n",
    "    for uid, user_ratings in top_n.items():\n",
    "        user_ratings.sort(key=lambda x: x[1], reverse=True)\n",
    "        top_n[uid] = user_ratings[:n]\n",
    "\n",
    "    return top_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_predict_save(algo, train_set, test_set, n_predictions, dump_path):\n",
    "    algo.fit(train_set)\n",
    "    predictions_algo = algo.test(test_set)\n",
    "    top_n_predictions = get_top_n(predictions_algo, n=n_predictions)\n",
    "    \n",
    "    dump.dump(dump_path, predictions_algo, algo)\n",
    "    \n",
    "    return predictions_algo, top_n_predictions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configurações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = \"./datasets/Refined/dataset.parquet\"\n",
    "TEST_SIZE = .25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 608\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "      <th>userId</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>[Adventure, Animation, Children, Comedy, Fantasy]</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>[Adventure, Animation, Children, Comedy, Fantasy]</td>\n",
       "      <td>5</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>[Adventure, Animation, Children, Comedy, Fantasy]</td>\n",
       "      <td>7</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>[Adventure, Animation, Children, Comedy, Fantasy]</td>\n",
       "      <td>15</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>[Adventure, Animation, Children, Comedy, Fantasy]</td>\n",
       "      <td>17</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movieId             title  \\\n",
       "0        1  Toy Story (1995)   \n",
       "1        1  Toy Story (1995)   \n",
       "2        1  Toy Story (1995)   \n",
       "3        1  Toy Story (1995)   \n",
       "4        1  Toy Story (1995)   \n",
       "\n",
       "                                              genres  userId  rating  \n",
       "0  [Adventure, Animation, Children, Comedy, Fantasy]       1     4.0  \n",
       "1  [Adventure, Animation, Children, Comedy, Fantasy]       5     4.0  \n",
       "2  [Adventure, Animation, Children, Comedy, Fantasy]       7     4.5  \n",
       "3  [Adventure, Animation, Children, Comedy, Fantasy]      15     2.5  \n",
       "4  [Adventure, Animation, Children, Comedy, Fantasy]      17     4.5  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_parquet(DATASET_PATH)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_rating = data[\"rating\"].min()\n",
    "max_rating = data[\"rating\"].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = Reader(rating_scale=(min_rating, max_rating))\n",
    "dataset = Dataset.load_from_df(data[['userId', 'movieId', 'rating']], reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Evaluating RMSE, MAE of algorithm BaselineOnly on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    0.8736  0.8724  0.8714  0.8796  0.8646  0.8723  0.0048  \n",
      "MAE (testset)     0.6741  0.6729  0.6700  0.6776  0.6681  0.6725  0.0033  \n",
      "Fit time          0.38    0.46    0.41    0.36    0.38    0.40    0.03    \n",
      "Test time         0.33    0.16    0.19    0.16    0.09    0.19    0.08    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_rmse': array([0.87361888, 0.87242742, 0.87135281, 0.87955244, 0.86462855]),\n",
       " 'test_mae': array([0.67409083, 0.67289043, 0.66995537, 0.67764192, 0.66810451]),\n",
       " 'fit_time': (0.38080358505249023,\n",
       "  0.4603300094604492,\n",
       "  0.4133784770965576,\n",
       "  0.3617537021636963,\n",
       "  0.38141942024230957),\n",
       " 'test_time': (0.32924795150756836,\n",
       "  0.16267824172973633,\n",
       "  0.1921064853668213,\n",
       "  0.16463232040405273,\n",
       "  0.0883629322052002)}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_validate(BaselineOnly(), dataset, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, test_set = train_test_split(dataset, test_size=TEST_SIZE)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix Factorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVD RMSE SCORE: 0.8757767254296172\n",
      "SVD MAE SCORE: 0.6757611050144046\n",
      "SVD BEST PARAMS RMSE: {'n_factors': 50, 'n_epochs': 50, 'lr_all': 0.005, 'reg_all': 0.4} \n",
      "\n",
      "SVD BEST PARAMS MAE: {'n_factors': 50, 'n_epochs': 50, 'lr_all': 0.005, 'reg_all': 0.4} \n",
      "\n",
      "['Goodfellas (1990)', 'Apocalypse Now (1979)', 'Raiders of the Lost Ark (Indiana Jones and the Raiders of the Lost Ark) (1981)', 'Monty Python and the Holy Grail (1975)', \"Schindler's List (1993)\", 'Fargo (1996)', 'Silence of the Lambs, The (1991)', 'Shining, The (1980)', 'Office Space (1999)', 'L.A. Confidential (1997)']\n"
     ]
    }
   ],
   "source": [
    "svd_algo = build_svg_algo(SVD, dataset, verbose=True)\n",
    "predictions_svd, top_n_svd = fit_predict_save(\n",
    "    svd_algo,\n",
    "    train_set,\n",
    "    test_set,\n",
    "    10,\n",
    "    \"./algo/svd_algo\"\n",
    ")\n",
    "\n",
    "\n",
    "for uid, user_ratings in top_n_svd.items():\n",
    "    if(uid == 1):\n",
    "        print([data[data[\"movieId\"]==iid][\"title\"].values[0] for (iid, _) in user_ratings])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m svd_pp_algo \u001b[39m=\u001b[39m build_svg_algo(SVDpp, dataset, verbose\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m      2\u001b[0m predictions_svd_pp, top_n_svd_pp \u001b[39m=\u001b[39m fit_predict_save(\n\u001b[1;32m      3\u001b[0m     svd_pp_algo,\n\u001b[1;32m      4\u001b[0m     train_set,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m./algo/svd_plus_plus_algo\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m      8\u001b[0m )\n\u001b[1;32m     10\u001b[0m \u001b[39mfor\u001b[39;00m uid, user_ratings \u001b[39min\u001b[39;00m top_n_svd_pp\u001b[39m.\u001b[39mitems():\n",
      "Cell \u001b[0;32mIn[28], line 26\u001b[0m, in \u001b[0;36mbuild_svg_algo\u001b[0;34m(prediction_algorithm, dataset, verbose)\u001b[0m\n\u001b[1;32m     16\u001b[0m param_grid \u001b[39m=\u001b[39m param_grid_nmf \u001b[39mif\u001b[39;00m \u001b[39mtype\u001b[39m(prediction_algorithm) \u001b[39m==\u001b[39m NMF \u001b[39melse\u001b[39;00m param_grid_svg\n\u001b[1;32m     18\u001b[0m gs \u001b[39m=\u001b[39m GridSearchCV(\n\u001b[1;32m     19\u001b[0m         prediction_algorithm,\n\u001b[1;32m     20\u001b[0m         param_grid,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     23\u001b[0m         n_jobs\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m\n\u001b[1;32m     24\u001b[0m )\n\u001b[0;32m---> 26\u001b[0m gs\u001b[39m.\u001b[39;49mfit(dataset)\n\u001b[1;32m     28\u001b[0m \u001b[39mif\u001b[39;00m (verbose):\n\u001b[1;32m     29\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mSVD RMSE SCORE: \u001b[39m\u001b[39m{\u001b[39;00mgs\u001b[39m.\u001b[39mbest_score[\u001b[39m'\u001b[39m\u001b[39mrmse\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/surprise/model_selection/search.py:104\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     90\u001b[0m cv \u001b[39m=\u001b[39m get_cv(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcv)\n\u001b[1;32m     92\u001b[0m delayed_list \u001b[39m=\u001b[39m (\n\u001b[1;32m     93\u001b[0m     delayed(fit_and_score)(\n\u001b[1;32m     94\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39malgo_class(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    102\u001b[0m     )\n\u001b[1;32m    103\u001b[0m )\n\u001b[0;32m--> 104\u001b[0m out \u001b[39m=\u001b[39m Parallel(\n\u001b[1;32m    105\u001b[0m     n_jobs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_jobs,\n\u001b[1;32m    106\u001b[0m     pre_dispatch\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpre_dispatch,\n\u001b[1;32m    107\u001b[0m     verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mjoblib_verbose,\n\u001b[1;32m    108\u001b[0m )(delayed_list)\n\u001b[1;32m    110\u001b[0m (test_measures_dicts, train_measures_dicts, fit_times, test_times) \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mout)\n\u001b[1;32m    112\u001b[0m \u001b[39m# test_measures_dicts is a list of dict like this:\u001b[39;00m\n\u001b[1;32m    113\u001b[0m \u001b[39m# [{'mae': 1, 'rmse': 2}, {'mae': 2, 'rmse': 3} ...]\u001b[39;00m\n\u001b[1;32m    114\u001b[0m \u001b[39m# E.g. for 5 splits, the first 5 dicts are for the first param\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[39m# (n_parameters_combinations, n_splits). This way we can easily compute\u001b[39;00m\n\u001b[1;32m    122\u001b[0m \u001b[39m# the mean and std dev over all splits or over all param comb.\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/joblib/parallel.py:1098\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1095\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m   1097\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend\u001b[39m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1098\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mretrieve()\n\u001b[1;32m   1099\u001b[0m \u001b[39m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m elapsed_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_start_time\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/joblib/parallel.py:975\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    973\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    974\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, \u001b[39m'\u001b[39m\u001b[39msupports_timeout\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m--> 975\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39;49mget(timeout\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtimeout))\n\u001b[1;32m    976\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    977\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39mget())\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/joblib/_parallel_backends.py:567\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    564\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[1;32m    565\u001b[0m \u001b[39mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[1;32m    566\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 567\u001b[0m     \u001b[39mreturn\u001b[39;00m future\u001b[39m.\u001b[39;49mresult(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[1;32m    568\u001b[0m \u001b[39mexcept\u001b[39;00m CfTimeoutError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    569\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTimeoutError\u001b[39;00m \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.10/concurrent/futures/_base.py:453\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[1;32m    451\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__get_result()\n\u001b[0;32m--> 453\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_condition\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[1;32m    455\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[1;32m    456\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[0;32m/usr/lib/python3.10/threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[39mtry\u001b[39;00m:    \u001b[39m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    319\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m         waiter\u001b[39m.\u001b[39;49macquire()\n\u001b[1;32m    321\u001b[0m         gotit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    322\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "svd_pp_algo = build_svg_algo(SVDpp, dataset, verbose=True)\n",
    "predictions_svd_pp, top_n_svd_pp = fit_predict_save(\n",
    "    svd_pp_algo,\n",
    "    train_set,\n",
    "    test_set,\n",
    "    10,\n",
    "    \"./algo/svd_plus_plus_algo\"\n",
    ")\n",
    "\n",
    "for uid, user_ratings in top_n_svd_pp.items():\n",
    "    if(uid == 1):\n",
    "        print(uid, [data[data[\"movieId\"]==iid][\"title\"].values[0] for (iid, _) in user_ratings])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svd_nmf_algo = build_svg_algo(NMF, dataset, verbose=True)\n",
    "predictions_svd_nmf, top_n_svd_nmf = fit_predict_save(\n",
    "    svd_nmf_algo,\n",
    "    train_set,\n",
    "    test_set,\n",
    "    10,\n",
    "    \"./algo/nmf_algo\"\n",
    ")\n",
    "\n",
    "for uid, user_ratings in top_n_svd_nmf.items():\n",
    "    if(uid == 1):\n",
    "        print(uid, [data[data[\"movieId\"]==iid][\"title\"].values[0] for (iid, _) in user_ratings])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_basic_algo = build_knn_algo(KNNBasic, dataset, verbose=False)\n",
    "predictions_knn_basic , top_n_knn_basic = fit_predict_save(\n",
    "    knn_basic_algo,\n",
    "    train_set,\n",
    "    test_set,\n",
    "    10,\n",
    "    \"knn_basic_algo\"\n",
    ")\n",
    "\n",
    "for uid, user_ratings in top_n_knn_basic.items():\n",
    "    if(uid == 1):\n",
    "        print([data[data[\"movieId\"]==iid][\"title\"].values[0] for (iid, _) in user_ratings])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_baseline_algo = build_knn_algo(KNNBaseline, dataset, verbose=False)\n",
    "predictions_knn_baseline , top_n_knn_baseline = fit_predict_save(\n",
    "    knn_baseline_algo,\n",
    "    train_set,\n",
    "    test_set,\n",
    "    10,\n",
    "    \"knn_baseline_algo\"\n",
    ")\n",
    "\n",
    "for uid, user_ratings in top_n_knn_baseline.items():\n",
    "    if(uid == 1):\n",
    "        print([data[data[\"movieId\"]==iid][\"title\"].values[0] for (iid, _) in user_ratings])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_with_z_score_algo = build_knn_algo(KNNWithZScore, dataset, verbose=False)\n",
    "predictions_knn_with_means , top_n_knn_with_z_score = fit_predict_save(\n",
    "    knn_with_z_score_algo,\n",
    "    train_set,\n",
    "    test_set,\n",
    "    10,\n",
    "    \"knn_with_z_score\"\n",
    ")\n",
    "\n",
    "for uid, user_ratings in top_n_knn_with_z_score.items():\n",
    "    if(uid == 1):\n",
    "        print([data[data[\"movieId\"]==iid][\"title\"].values[0] for (iid, _) in user_ratings])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_with_means_algo = build_knn_algo(KNNWithMeans, dataset, verbose=False)\n",
    "predictions_knn_with_means, top_n_knn_with_means = fit_predict_save(\n",
    "    knn_with_means_algo,\n",
    "    train_set,\n",
    "    test_set,\n",
    "    10,\n",
    "    \"knn_with_means_algo\"\n",
    ")\n",
    "\n",
    "for uid, user_ratings in top_n_knn_with_means.items():\n",
    "    if(uid == 1):\n",
    "        print([data[data[\"movieId\"]==iid][\"title\"].values[0] for (iid, _) in user_ratings])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
